{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AND gate using NN from scratch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial we will build a simple neural network from scratch. Please note this code has no details so either you contact me if you need help or refer to other description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First: we need to define inputs and we will let it simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 2)\n"
     ]
    }
   ],
   "source": [
    "input_features=np.array([[0,0],[0,1],[1,0],[1,1]])\n",
    "print (input_features.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we have 4 rows and two columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second Let's define target. let it be an and gate.so and is equal to one when both numbers are one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 1)\n"
     ]
    }
   ],
   "source": [
    "target=np.array([[0],[0],[0],[1]])\n",
    "print (target.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assign the bise, weight, and learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "weights = np.random.rand(2,1)\n",
    "bias = np.random.rand(1)\n",
    "learrning_rate = 0.05\n",
    "#learning rate should be small. We want the algorithm make optimization to let the error small. So it must start with small number to make the algorithm optimize the number and make it small in each iteration. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define sigmoid and the derivative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "# Derivative of sigmoid function:\n",
    "def sigmoid_der(x):\n",
    "    return sigmoid(x)*(1-sigmoid(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10000): # make the network itterate 10000 time\n",
    "    #Feedforward input\n",
    "    inputs = input_features\n",
    "    inputs_fed= np.dot(inputs, weights) + bias    \n",
    "    \n",
    "    #Feedforward output\n",
    "    output_fed = sigmoid(inputs_fed) \n",
    "\n",
    "    #Calculating error\n",
    "    error = output_fed - target\n",
    "    error_sum=error.sum()       \n",
    "    \n",
    "#lets see the dervaitive equations\n",
    "\n",
    "# derror/dw=derorr/d output_fed* d output_fed/ d inputs_fed * d inputs_fed* d w\n",
    "# let find each component individually\n",
    "#derorr/d output_fed= output_fed-output which equal to error\n",
    "    derror_over_doutput_fed = error\n",
    "\n",
    "#d output_fed/ d inputs_fed = second dervaitve of sigmid\n",
    "    d_output_fed_d_inputs_fed = sigmoid_der(output_fed)\n",
    "\n",
    "#Multiplying\n",
    "    deriv = derror_over_doutput_fed * d_output_fed_d_inputs_fed\n",
    "\n",
    "#Multiplying with the 3rd individual component:\n",
    "    inputs = input_features.T\n",
    "    deriv_final = np.dot(inputs,deriv)\n",
    "\n",
    "#update weight and biase\n",
    "    weights -= learrning_rate * deriv_final \n",
    "#Updating the bias weight value:\n",
    "for g in deriv:\n",
    "    bias -= learrning_rate * g #Check the final values for weight and biasprint (weights)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict the values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.93257961]\n"
     ]
    }
   ],
   "source": [
    "single_point = np.array([1,1])\n",
    "result = sigmoid(np.dot(single_point, weights) + bias)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So it is near to one"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "try another point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.03901505]\n"
     ]
    }
   ],
   "source": [
    "single_point2 = np.array([0,1])\n",
    "result2 = sigmoid(np.dot(single_point2, weights) + bias)\n",
    "print(result2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result of 0 and one is Near to zero"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "conclusion: in this tutorial we build and gate using NN from scratch"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
